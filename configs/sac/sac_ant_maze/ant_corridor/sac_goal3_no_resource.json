{
    "base_config_file": "configs/sac/sac.json",
    "experiment":{
        "tag": "my_sac",
        "use_gpu": true,
        "seed": null,
        "base_log_dir": "/home/rl_shared/zhihaiwang/research/ICML_data/exploration_env_exps_fix_env/ant_corridor/sac_no_entropy_q_no_resource/goal3",
        "exp_prefix": "sac_no_resource_goal3"
    },
    "algorithm": {
        "name": "sac",
        "class": "batch_RL_algorithm",
        "kwargs": {
            "num_epochs": 1000,
            "batch_size": 256,
            "num_eval_steps_per_epoch":8000,
            "num_train_loops_per_epoch": 1000,
            "num_expl_steps_per_train_loop": 1,
            "num_trains_per_train_loop": 1,
            "min_num_steps_before_training": 5000,
            "record_video_freq": 10,
            "max_path_length": 400,
            "silent": false
        }
    },
    "environment": [
        {
            "name": "expl_env",
            "class": "simple_env",
            "kwargs": {
                "env_name": "ant_corridor_env_3",
                "reward_scale": 1
            }
        },
        {
            "name": "eval_env",
            "class": "normalized_vector_env",
            "kwargs": {
                "env_name": "ant_corridor_env_3",
                "n_env":8,
                "reward_scale": 1
            }
        },
        {
            "name": "video_env",
            "class": "video_env",
            "kwargs": {
                "env_name": "ant_corridor_env_3"
            }
        }
    ]
}