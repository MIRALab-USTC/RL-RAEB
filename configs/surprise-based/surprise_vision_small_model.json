{
    "experiment":{
        "tag": "surprise_vision",
        "use_gpu": true,
        "seed": null,
        "base_log_dir": "/home/zhwang/research/ICML_data/exploration_env_exps_fix_env/mountain_car_normalize_discrete_resource/surprise_vision",
        "exp_prefix": "mountain_car_surprise_vision"
    },
    "algorithm": {
        "name": "model_based_sac_surprise",
        "class": "ModelBasedBatchRLAlgorithm",
        "kwargs": {
            "num_epochs": 1000,
            "batch_size": 256,
            "num_eval_steps_per_epoch":4000,
            "num_train_loops_per_epoch": 1000,
            "num_expl_steps_per_train_loop": 1,
            "num_trains_per_train_loop": 1,
            "num_train_models_per_epoch": 1000,
            "max_path_length": 200,
            "train_model_freq": 500,
            "model_normalize": true,
            "save_model_freq": 1,
            "min_num_steps_before_training": 5000,
            "record_video_freq": 10,
            "silent": false
        }
    },
    "environment": [
        {
            "name": "expl_env",
            "class": "simple_env",
            "kwargs": {
                "env_name": "ant_maze_resource_block2_4",
                "reward_scale": 1
            }
        },
        {
            "name": "eval_env",
            "class": "normalized_vector_env",
            "kwargs": {
                "env_name": "ant_maze_resource_block2_4",
                "n_env":8,
                "reward_scale": 1
            }
        },
        {
            "name": "video_env",
            "class": "video_env",
            "kwargs": {
                "env_name": "ant_maze"
            }
        }
    ],
    "policy": [
        {
            "name": "init_expl_policy",
            "class": "uniformly_random_policy",
            "kwargs":{
                "env": "$expl_env"
            }
        },
        {
            "name": "policy",
            "class": "gaussian_policy",
            "kwargs": {
                "env": "$expl_env",
                "hidden_layers":  [32],
                "nonlinearity": "relu"
            }
        },
        {
            "name": "eval_policy",
            "class": "MakeDeterministic",
            "kwargs":{
                "random_policy": "$policy"
            }
        }
    ],
    "value": {
        "name": "qf",
        "class": "ensemble_q_value",
        "kwargs": {
            "env": "$expl_env",
            "hidden_layers": [32]
        } 
    },
    "model": {
        "name": "model_without_reward",
        "class": "model_no_reward",
        "kwargs": {
            "env": "$expl_env",
            "layers_num": 0, 
            "hidden_size": [32],
            "ensemble_size": 1, 
            "non_linearity": "swish"   
        }
    },
    "trainer":{
        "name": "trainer",
        "class": "Vision_Surprise_SAC_Trainer",
        "kwargs": {
            "env": "$expl_env",
            "policy": "$policy",
            "qf": "$qf",
            "model": "$model_without_reward",
            "intrinsic_coeff": 0.05,
            "int_coeff_decay": false,
            "intrinsic_normal": false,
            "alg_type": "surprise",
            "measure_decay": 0.1, 
            "max_step": 1e6,
            "model_lr": 3e-4,
            "training_noise_stdev": 0.1,
            "grad_clip": 1,
            "reward_scale":1,
            "policy_lr": 3e-4,
            "shape_env_weight": true,
            "qf_lr": 3e-4,
            "soft_target_tau": 5e-3,
            "use_automatic_entropy_tuning": true,
            "alpha_if_not_automatic": 0,
            "discount": 0.99
        }
    },
    "pool": {
        "name": "pool",
        "class": "normalize_simple_pool",
        "kwargs": {
            "env": "$expl_env",
            "max_size": 3e6
        }
    },
    "collector": [
        {
            "name": "expl_collector",
            "class": "simple_step_collector",
            "kwargs": {
                "env": "$expl_env",
                "policy": "$policy"
            }
        },
        {
            "name": "eval_collector",
            "class": "simple_path_collector",
            "kwargs": {
                "env": "$eval_env",
                "policy": "$eval_policy"
            }
        }
    ]
}